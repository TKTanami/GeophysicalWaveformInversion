{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad457f97-dc52-4e41-8a4d-5acfbacbd607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ğŸ”¹ 1. å®Ÿæ³¢å½¢ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å®šç¾©\n",
    "class WaveformDataset(Dataset):\n",
    "    def __init__(self, waveform_data):  # waveform_data: [N, 5, 1000, 7]\n",
    "        self.data = waveform_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bac6e1-b3c6-4d30-88d7-04af2673d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# âœ… æ­£ã—ã„æ§‹æˆæ¡ˆï¼šForward PINN + Inverse CNN\n",
    "# =======================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1. Velocity Map Decoder (CNN) : æ³¢å½¢ â†’ é€Ÿåº¦ãƒãƒƒãƒ—\n",
    "class InverseVelocityDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 16, (3, 5, 3), padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool3d((1, 10, 10))\n",
    "        self.fc = nn.Linear(32 * 10 * 10, 1024)\n",
    "        self.out = nn.Linear(1024, 70 * 70)\n",
    "\n",
    "    def forward(self, x):  # x: [B, 5, 1000, 7]\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return self.out(x).view(-1, 1, 70, 70)\n",
    "\n",
    "# 2. WaveNet: Forward PINN ãƒ¢ãƒ‡ãƒ« u(x,z,t)\n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, in_dim=3, hidden=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, xzt):  # xzt: [B, 3]\n",
    "        return self.net(xzt)\n",
    "\n",
    "# 3. VelocityMapFn: V(x,z) ã‚’é€£ç¶šé–¢æ•°ã«å¤‰æ›\n",
    "class VelocityMapFn(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, waveform, coords):  # coords: [B, 2]\n",
    "        v_grid = self.model(waveform)  # [B, 1, 70, 70]\n",
    "        coords = (coords + 1) / 2\n",
    "        coords = coords.unsqueeze(1).unsqueeze(1)\n",
    "        return F.grid_sample(v_grid, coords, align_corners=True).view(-1, 1)\n",
    "\n",
    "# 4. PDEæ®‹å·®è¨ˆç®—ï¼ˆForward PINN Lossï¼‰\n",
    "def compute_pde_residual(u_model, v_fn, waveform, xzt):\n",
    "    xzt.requires_grad_(True)\n",
    "    u = u_model(xzt)\n",
    "    grads = torch.autograd.grad(u, xzt, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    u_x, u_z, u_t = grads[:, 0:1], grads[:, 1:2], grads[:, 2:3]\n",
    "    u_xx = torch.autograd.grad(u_x, xzt, grad_outputs=torch.ones_like(u_x), create_graph=True)[0][:, 0:1]\n",
    "    u_zz = torch.autograd.grad(u_z, xzt, grad_outputs=torch.ones_like(u_z), create_graph=True)[0][:, 1:2]\n",
    "    u_tt = torch.autograd.grad(u_t, xzt, grad_outputs=torch.ones_like(u_t), create_graph=True)[0][:, 2:3]\n",
    "\n",
    "    v = v_fn(waveform, xzt[:, :2])\n",
    "    residual = u_tt - v**2 * (u_xx + u_zz)\n",
    "    return residual\n",
    "\n",
    "# ---------------------------------------\n",
    "# æ¨è«–ï¼šCNN (æ³¢å½¢ â†’ V) ã«å¯¾ã—ã€Forward PINNã§ u(x,z,t) ã‚’å†æ§‹æˆ\n",
    "# â†’ PDEæå¤±ï¼ˆç‰©ç†æ•´åˆï¼‰ã‚’é€šã˜ã¦CNNã‚’é–“æ¥çš„ã«è¨“ç·´ã™ã‚‹\n",
    "# ---------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04419bae-310e-42ea-a4ce-c3c9cfe2d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ğŸ”¹ åº§æ¨™ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é–¢æ•°ï¼ˆx, z, tï¼‰ âˆˆ [-1, 1]^3\n",
    "def sample_coords(batch_size):\n",
    "    # å‡ç­‰ãªä¹±æ•°ã‚’ [-1, 1] ã®ç¯„å›²ã§ç”Ÿæˆï¼ˆB, 3ï¼‰\n",
    "    return 2.0 * torch.rand(batch_size, 3) - 1.0\n",
    "\n",
    "# # ğŸ”¹ å­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆForward PINN + Inverse CNNï¼‰\n",
    "# def train_forward_pinn(\n",
    "#     waveform_encoder, velocity_map_fn, wave_model,\n",
    "#     train_loader, optimizer, device,\n",
    "#     epochs=100, best_model_path=\"best_model.pth\"\n",
    "# ):\n",
    "#     best_loss = float('inf')\n",
    "#     for epoch in range(epochs):\n",
    "#         waveform_encoder.train()\n",
    "#         velocity_map_fn.train()\n",
    "#         wave_model.train()\n",
    "#         total_loss = 0.0\n",
    "\n",
    "#         for waveform_batch in train_loader:  # waveform_batch: [B, 5, 1000, 7]\n",
    "#             waveform_batch = waveform_batch.to(device)\n",
    "#             batch_size = waveform_batch.size(0)\n",
    "#             xzt = sample_coords(batch_size=512).to(device)  # å›ºå®šã‚µãƒ³ãƒ—ãƒ«æ•°\n",
    "\n",
    "#             # PDEæå¤±ã‚’è¨ˆç®—ï¼ˆForward PINNï¼‰\n",
    "#             residual = compute_pde_residual(wave_model, velocity_map_fn, waveform_batch, xzt)\n",
    "#             loss_pde = (residual ** 2).mean()\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss_pde.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             total_loss += loss_pde.item()\n",
    "\n",
    "#         avg_loss = total_loss / len(train_loader)\n",
    "#         print(f\"Epoch {epoch+1}/{epochs} | PDE Loss: {avg_loss:.6f}\")\n",
    "\n",
    "#         if avg_loss < best_loss:\n",
    "#             best_loss = avg_loss\n",
    "#             torch.save(waveform_encoder.state_dict(), best_model_path)\n",
    "#             print(f\"âœ… Best model saved at epoch {epoch+1} with loss {best_loss:.6f}\")\n",
    "\n",
    "#     print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa8ca7c-eaee-4e60-92fc-7d903ea10ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ğŸ”¹ 2. å­¦ç¿’ + æ¤œè¨¼ãƒ«ãƒ¼ãƒ—ï¼ˆval_loaderä»˜ãï¼‰\n",
    "def train_forward_pinn_with_val(\n",
    "    waveform_encoder, velocity_map_fn, wave_model,\n",
    "    train_loader, val_loader, optimizer, device,\n",
    "    epochs=100, best_model_path=\"best_forward_pinn_model.pth\"\n",
    "):\n",
    "    best_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        waveform_encoder.train()\n",
    "        wave_model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for waveform_batch in train_loader:\n",
    "            waveform_batch = waveform_batch.to(device)\n",
    "            xzt = sample_coords(batch_size=512).to(device)\n",
    "\n",
    "            residual = compute_pde_residual(wave_model, velocity_map_fn, waveform_batch, xzt)\n",
    "            loss_pde = (residual ** 2).mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_pde.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss_pde.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # --- æ¤œè¨¼ãƒ«ãƒ¼ãƒ— ---\n",
    "        waveform_encoder.eval()\n",
    "        wave_model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for waveform_batch in val_loader:\n",
    "                waveform_batch = waveform_batch.to(device)\n",
    "                xzt = sample_coords(batch_size=512).to(device)\n",
    "                residual = compute_pde_residual(wave_model, velocity_map_fn, waveform_batch, xzt)\n",
    "                loss_pde = (residual ** 2).mean()\n",
    "                val_loss += loss_pde.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train: {avg_train_loss:.6f} | Val: {avg_val_loss:.6f}\")\n",
    "\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(waveform_encoder.state_dict(), best_model_path)\n",
    "            print(f\"âœ… Best model saved at epoch {epoch+1} with val loss {best_loss:.6f}\")\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "    return train_losses, val_losses\n",
    "\n",
    "# ğŸ”¹ 3. Losså¯è¦–åŒ–é–¢æ•°\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('PDE Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training vs Validation Loss')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# ğŸ”¹ 4. é€Ÿåº¦ãƒãƒƒãƒ—å¯è¦–åŒ–é–¢æ•°\n",
    "def visualize_velocity_map(velocity_tensor):\n",
    "    # velocity_tensor: [1, 1, 70, 70]\n",
    "    velocity_map = velocity_tensor.detach().cpu().squeeze().numpy()\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(velocity_map, cmap='viridis', origin='lower')\n",
    "    plt.colorbar(label='Velocity (m/s)')\n",
    "    plt.title('Predicted Velocity Map')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Z')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c4e87-ec0a-49f2-bdd2-43dc6c783fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# äºˆæ¸¬ç”¨: ãƒ¢ãƒ‡ãƒ«ã‚’æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã«\n",
    "waveform_encoder.eval()\n",
    "\n",
    "n_show = 5  # è¡¨ç¤ºã—ãŸã„ã‚µãƒ³ãƒ—ãƒ«æ•°\n",
    "\n",
    "with torch.no_grad():\n",
    "    xb, yb = next(iter(val_loader))\n",
    "    xb = xb.to(device)\n",
    "    yb = yb.to(device)\n",
    "    v_pred = waveform_encoder(xb)  # [B,1,70,70]\n",
    "\n",
    "# æç”»\n",
    "fig, axes = plt.subplots(n_show, 2, figsize=(8, n_show*3))\n",
    "\n",
    "for i in range(n_show):\n",
    "    # 0ç•ªç›®ã‹ã‚‰n_showç•ªç›®ã¾ã§\n",
    "    pred_img = v_pred[i, 0].detach().cpu().numpy()  # [70,70]\n",
    "    gt_img   = yb[i, 0].detach().cpu().numpy()      # [70,70]\n",
    "\n",
    "    # æ­£è§£\n",
    "    ax_gt = axes[i, 0]\n",
    "    im_gt = ax_gt.imshow(gt_img, cmap=\"jet\", aspect='auto')\n",
    "    ax_gt.set_title(f\"Ground Truth #{i}\")\n",
    "    fig.colorbar(im_gt, ax=ax_gt, fraction=0.046, pad=0.04)\n",
    "    ax_gt.axis(\"off\")\n",
    "\n",
    "    # äºˆæ¸¬\n",
    "    ax_pred = axes[i, 1]\n",
    "    im_pred = ax_pred.imshow(pred_img, cmap=\"jet\", aspect='auto')\n",
    "    ax_pred.set_title(f\"Prediction #{i}\")\n",
    "    fig.colorbar(im_pred, ax=ax_pred, fraction=0.046, pad=0.04)\n",
    "    ax_pred.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
