{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba69cdc",
   "metadata": {},
   "source": [
    "# testを読み込んでsubmission.csvを出力する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9419351b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c621080",
   "metadata": {},
   "source": [
    "# 適切なモデル構造を最初に作って、その後に学習済みモデルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3289c03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WaveformUNet(\n",
       "  (inc): DoubleConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): DoubleConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): DoubleConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): DoubleConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bot): DoubleConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (dec3): DoubleConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (dec2): DoubleConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (dec1): DoubleConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (outc): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"2回連続 Conv→BN→ReLU のブロック\"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class WaveformUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # --- Encoder ---\n",
    "        self.inc   = DoubleConv(5,  32)              # 入力波形 5ch→32ch, size=(1000,70)\n",
    "        self.down1 = nn.Sequential(nn.MaxPool2d((2,2)), DoubleConv(32, 64))   # →(500,35)\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d((2,2)), DoubleConv(64,128))   # →(250,17)\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2d((2,2)), DoubleConv(128,256))  # →(125,8)\n",
    "        # --- Bottleneck ---\n",
    "        self.bot   = DoubleConv(256, 256)           # →(125,8)\n",
    "        # --- Decoder ---\n",
    "        self.up3   = nn.ConvTranspose2d(256,128,kernel_size=2,stride=2)  # →(250,16)\n",
    "        self.dec3  = DoubleConv(256,128)\n",
    "        self.up2   = nn.ConvTranspose2d(128,64, kernel_size=2,stride=2)  # →(500,32)\n",
    "        self.dec2  = DoubleConv(128,64)\n",
    "        self.up1   = nn.ConvTranspose2d(64,32,  kernel_size=2,stride=2)  # →(1000,64)\n",
    "        self.dec1  = DoubleConv(64,32)\n",
    "        # --- Final conv ---\n",
    "        self.outc  = nn.Conv2d(32, 1, kernel_size=1)  # →(1000,64)→(1000,1,64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.inc(x)       # [B,32,1000,70]\n",
    "        x2 = self.down1(x1)    # [B,64,500,35]\n",
    "        x3 = self.down2(x2)    # [B,128,250,17]\n",
    "        x4 = self.down3(x3)    # [B,256,125,8]\n",
    "        # Bottleneck\n",
    "        xb = self.bot(x4)      # [B,256,125,8]\n",
    "        # Decoder + skip connections\n",
    "        x = self.up3(xb)                                 # [B,128,250,16]\n",
    "        x = torch.cat([x, x3[:,:, :250, :16]], dim=1)    # チャネル結合\n",
    "        x = self.dec3(x)                                 # [B,128,250,16]\n",
    "        x = self.up2(x)                                  # [B,64,500,32]\n",
    "        x = torch.cat([x, x2[:,:, :500, :32]], dim=1)\n",
    "        x = self.dec2(x)                                 # [B,64,500,32]\n",
    "        x = self.up1(x)                                  # [B,32,1000,64]\n",
    "        x = torch.cat([x, x1[:,:, :1000, :64]], dim=1)\n",
    "        x = self.dec1(x)                                 # [B,32,1000,64]\n",
    "        # 最終出力\n",
    "        x = self.outc(x)  # [B,1,1000,64]\n",
    "        # --- 時間軸(1000)→70 & 空間軸(64)→70 に縮小 ---\n",
    "        x = F.adaptive_avg_pool2d(x, (70, 70))  # → [B,1,70,70]\n",
    "        return x\n",
    "\n",
    "# Load pretrained model\n",
    "model = WaveformUNet().to(device)\n",
    "checkpoint = torch.load('best_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe5744",
   "metadata": {},
   "source": [
    "# 学習済みモデルでテストデータに対して推論。その後csvデータを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a521616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress:   9%|██▍                         | 728/8228 [01:40<17:05,  7.31it/s]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm  # 追加\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "test_dir = './waveform-inversion/test'\n",
    "test_files = sorted([os.path.join(test_dir, f) for f in os.listdir(test_dir) if f.endswith('.npy')])\n",
    "\n",
    "batch_size = 8  # 調整可能\n",
    "\n",
    "rows = []\n",
    "\n",
    "# tqdmでプログレスバー表示\n",
    "for i in tqdm(range(0, len(test_files), batch_size), desc=\"Inference Progress\"):\n",
    "    batch_files = test_files[i:i+batch_size]\n",
    "    batch_arrs = [np.load(fp) for fp in batch_files]  # list of arrays (5,1000,70)\n",
    "    batch_tensor = torch.from_numpy(np.stack(batch_arrs)).float().to(device)  # (B,5,1000,70)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outs = model(batch_tensor)  # (B,1,70,70)\n",
    "\n",
    "    outs = outs.squeeze(1).cpu().numpy()  # (B,70,70)\n",
    "\n",
    "    for b, fp in enumerate(batch_files):\n",
    "        fid = os.path.splitext(os.path.basename(fp))[0]\n",
    "        out = outs[b]\n",
    "        for y in range(out.shape[0]):\n",
    "            row = {'oid_ypos': f'{fid}_y_{y}'}\n",
    "            x_vals = {f'x_{2*j+1}': out[y, xpos] for j, xpos in enumerate(range(0, 70, 2))}\n",
    "            row.update(x_vals)\n",
    "            rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "cols = ['oid_ypos'] + [f'x_{i}' for i in range(1, 70, 2)]\n",
    "df = df[cols]\n",
    "\n",
    "df.head()\n",
    "# df.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
