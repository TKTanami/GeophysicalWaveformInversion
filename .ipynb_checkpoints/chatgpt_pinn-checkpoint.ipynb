{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dcb7995",
   "metadata": {},
   "source": [
    "[æ³¢å½¢ãƒ‡ãƒ¼ã‚¿] (5, 1000, 7)\n",
    "   â†“\n",
    "Encoder CNN / Transformer\n",
    "   â†“\n",
    "[é€Ÿåº¦ãƒãƒƒãƒ—] (1, 70, 70)        â† ã“ã®å‡ºåŠ›ã«å¯¾ã—â€¦\n",
    "   â†“\n",
    "VelocityMapFn (é€£ç¶šé–¢æ•°åŒ–)\n",
    "   â†“\n",
    "PINNæå¤± (æ³¢å‹•æ–¹ç¨‹å¼ âˆ‚Â²u/âˆ‚tÂ² = VÂ²(âˆ‚Â²u/âˆ‚xÂ² + âˆ‚Â²u/âˆ‚zÂ²))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23771c6",
   "metadata": {},
   "source": [
    "ğŸ§© 1. æ³¢å½¢ â†’ é€Ÿåº¦ãƒãƒƒãƒ—ãƒ¢ãƒ‡ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07c098f4-0c5a-4173-a76a-f5439563e4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1f2199-641d-4819-a82d-7fecda46513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ç›´å¾Œã«ä¸€åº¦ã ã‘è¨ˆç®—ã—ã¦ãŠã\n",
    "all_vels = np.load(\"./dataset_one_batch/train_vels.npy\")   # shape (800,1,70,70)\n",
    "vel_min, vel_max = all_vels.min(), all_vels.max()\n",
    "\n",
    "# b) Dataset å†…ã§æ­£è¦åŒ–ï¼é€†æ­£è¦åŒ–\n",
    "class NormWaveformDataset(Dataset):\n",
    "    def __init__(self, waves_path, vels_path, vel_min, vel_max):\n",
    "        self.waves = np.load(waves_path).astype(np.float32)\n",
    "        self.vels  = np.load(vels_path).astype(np.float32)\n",
    "        self.vmin, self.vmax = vel_min, vel_max\n",
    "\n",
    "    def __len__(self): return len(self.waves)\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.waves[idx]\n",
    "        # æ³¢å½¢ã¯ global çµ±è¨ˆã§æ¨™æº–åŒ–ã—ã¦ã‚‚è‰¯ã„ã§ã™ï¼ˆã“ã“ã§ã¯ç°¡æ˜“ã« min-maxï¼‰\n",
    "        x = (x - x.min()) / (x.max() - x.min())\n",
    "        y = self.vels[idx]\n",
    "        # é€Ÿåº¦ã¯ [vel_min,vel_max] â†’ [0,1]\n",
    "        y_norm = (y - self.vmin) / (self.vmax - self.vmin)\n",
    "        return torch.from_numpy(x).float(), torch.from_numpy(y_norm).float()\n",
    "\n",
    "# c) DataLoader ä½œæˆï¼ˆnum_workers=0 æ¨å¥¨ï¼‰\n",
    "train_ds = NormWaveformDataset(\"./dataset_one_batch/train_waves.npy\",\n",
    "                               \"./dataset_one_batch/train_vels.npy\",\n",
    "                               vel_min, vel_max)\n",
    "val_ds   = NormWaveformDataset(\"./dataset_one_batch/val_waves.npy\",\n",
    "                               \"./dataset_one_batch/val_vels.npy\",\n",
    "                               vel_min, vel_max)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=16, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4732b4fc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class WaveformEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=(3, 5, 3), padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool3d((1, 10, 10))   # ç©ºé–“ç‰¹å¾´ã‚’ç¶­æŒï¼\n",
    "        self.fc = nn.Linear(32 * 10 * 10, 1024)\n",
    "        self.out = nn.Linear(1024, 70 * 70)\n",
    "\n",
    "    def forward(self, x):  # [B, 5, 1000, 7]\n",
    "        x = x.unsqueeze(1)  # [B,1,5,1000,7]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)                   # [B,32,1,10,10]\n",
    "        x = x.view(x.size(0), -1)          # [B, 32*10*10]\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = self.out(x)\n",
    "        return x.view(-1, 1, 70, 70)       # [B, 1, 70, 70]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c19ac9",
   "metadata": {},
   "source": [
    "ğŸ§® 2. é€Ÿåº¦ãƒãƒƒãƒ— â†’ é€£ç¶šé–¢æ•°åŒ–ï¼ˆgrid_sampleï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25ff3054",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class VelocityMapFn(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, waveform, coords):  # waveform: [B, 5, 1000, 7], coords: [B, 2]\n",
    "        v_grid = self.model(waveform)  # [B, 1, 70, 70]\n",
    "        coords = (coords + 1) / 2  # [-1, 1] â†’ [0, 1]\n",
    "        coords = coords.unsqueeze(1).unsqueeze(1)  # [B, 1, 1, 2]\n",
    "        return F.grid_sample(v_grid, coords, align_corners=True).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e88553e",
   "metadata": {},
   "source": [
    "ğŸ“ 3. æ³¢å‹•å ´ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ u(x,z,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0808df00",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, in_dim=3, hidden=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, xzt):  # [B, 3]\n",
    "        return self.net(xzt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8abccf-f8be-464f-9f2a-1bf5897e140f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b2277af",
   "metadata": {},
   "source": [
    "ğŸ“˜ 4. PDEæ®‹å·®ï¼ˆPINNæå¤±ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "676c937e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def compute_pde_residual(u_model, v_fn, waveform, xzt):\n",
    "    xzt.requires_grad_(True)\n",
    "    u = u_model(xzt)  # [B, 1]\n",
    "\n",
    "    grads = torch.autograd.grad(u, xzt, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    u_x, u_z, u_t = grads[:, 0:1], grads[:, 1:2], grads[:, 2:3]\n",
    "\n",
    "    u_xx = torch.autograd.grad(u_x, xzt, grad_outputs=torch.ones_like(u_x), create_graph=True)[0][:, 0:1]\n",
    "    u_zz = torch.autograd.grad(u_z, xzt, grad_outputs=torch.ones_like(u_z), create_graph=True)[0][:, 1:2]\n",
    "    u_tt = torch.autograd.grad(u_t, xzt, grad_outputs=torch.ones_like(u_t), create_graph=True)[0][:, 2:3]\n",
    "\n",
    "    v = v_fn(waveform, xzt[:, :2])  # x, zåº§æ¨™ã‹ã‚‰V(x,z)\n",
    "    residual = u_tt - v**2 * (u_xx + u_zz)\n",
    "    return residual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e583a",
   "metadata": {},
   "source": [
    "ğŸ” 5. å­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆPINN + data lossï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5394bbe4-a306-4c00-b4ee-809e7fc93155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã‚’ GPU ã«è¼‰ã›ã‚‹\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = WaveformUNet().to(device)\n",
    "model = WaveNet().to(device)\n",
    "\n",
    "\n",
    "# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ & ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©\n",
    "# optimizer = torch.optim.AdamW(wave_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "waveform_encoder = WaveformEncoder().to(device)\n",
    "optimizer = torch.optim.Adam(list(waveform_encoder.parameters()) + list(model.parameters()), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=3\n",
    ")\n",
    "criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91165745-a955-4924-8789-a096cb92cc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_coords(batch_size):\n",
    "    # ä¾‹ãˆã° tã ã‘[0, 1]ã€xã¨zã¯[-1, 1] ãªã©ã€ç‰©ç†è¨­å®šã«åˆã‚ã›ã‚‹\n",
    "    x = 2 * torch.rand(batch_size, 1) - 1\n",
    "    z = 2 * torch.rand(batch_size, 1) - 1\n",
    "    t = torch.rand(batch_size, 1)      # tã ã‘[0,1]ã¨ã‹\n",
    "    return torch.cat([x, z, t], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8596f77",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Loss: 0.070713 | Data: 0.070712 | PDE: 0.000108\n",
      "Epoch 2/100 | Loss: 0.050431 | Data: 0.050431 | PDE: 0.000006\n",
      "Epoch 3/100 | Loss: 0.050417 | Data: 0.050417 | PDE: 0.000013\n",
      "Epoch 4/100 | Loss: 0.048535 | Data: 0.048535 | PDE: 0.000009\n",
      "Epoch 5/100 | Loss: 0.051126 | Data: 0.051126 | PDE: 0.000016\n",
      "Epoch 6/100 | Loss: 0.049635 | Data: 0.049632 | PDE: 0.000305\n",
      "Epoch 7/100 | Loss: 0.050195 | Data: 0.050195 | PDE: 0.000033\n",
      "Epoch 8/100 | Loss: 0.049197 | Data: 0.049197 | PDE: 0.000000\n",
      "Epoch 9/100 | Loss: 0.048765 | Data: 0.048765 | PDE: 0.000000\n",
      "Epoch 10/100 | Loss: 0.049769 | Data: 0.049769 | PDE: 0.000000\n",
      "Epoch 11/100 | Loss: 0.048653 | Data: 0.048653 | PDE: 0.000000\n",
      "Epoch 12/100 | Loss: 0.048410 | Data: 0.048410 | PDE: 0.000000\n",
      "Epoch 13/100 | Loss: 0.048022 | Data: 0.048022 | PDE: 0.000000\n",
      "Epoch 14/100 | Loss: 0.048394 | Data: 0.048394 | PDE: 0.000000\n",
      "Epoch 15/100 | Loss: 0.048487 | Data: 0.048487 | PDE: 0.000000\n",
      "Epoch 16/100 | Loss: 0.048589 | Data: 0.048589 | PDE: 0.000000\n",
      "Epoch 17/100 | Loss: 0.048265 | Data: 0.048265 | PDE: 0.000000\n",
      "Epoch 18/100 | Loss: 0.047916 | Data: 0.047916 | PDE: 0.000000\n",
      "Epoch 19/100 | Loss: 0.048153 | Data: 0.048153 | PDE: 0.000000\n",
      "Epoch 20/100 | Loss: 0.048605 | Data: 0.048605 | PDE: 0.000000\n",
      "Epoch 21/100 | Loss: 0.048049 | Data: 0.048049 | PDE: 0.000000\n",
      "Epoch 22/100 | Loss: 0.047554 | Data: 0.047554 | PDE: 0.000000\n",
      "Epoch 23/100 | Loss: 0.047681 | Data: 0.047681 | PDE: 0.000000\n",
      "Epoch 24/100 | Loss: 0.047509 | Data: 0.047509 | PDE: 0.000000\n",
      "Epoch 25/100 | Loss: 0.047077 | Data: 0.047077 | PDE: 0.000000\n",
      "Epoch 26/100 | Loss: 0.046291 | Data: 0.046291 | PDE: 0.000000\n",
      "Epoch 27/100 | Loss: 0.045181 | Data: 0.045181 | PDE: 0.000000\n",
      "Epoch 28/100 | Loss: 0.043405 | Data: 0.043405 | PDE: 0.000000\n",
      "Epoch 29/100 | Loss: 0.040041 | Data: 0.040041 | PDE: 0.000000\n",
      "Epoch 30/100 | Loss: 0.038418 | Data: 0.038418 | PDE: 0.000000\n",
      "Epoch 31/100 | Loss: 0.039410 | Data: 0.039410 | PDE: 0.000000\n",
      "Epoch 32/100 | Loss: 0.038388 | Data: 0.038388 | PDE: 0.000000\n",
      "Epoch 33/100 | Loss: 0.038539 | Data: 0.038539 | PDE: 0.000000\n",
      "Epoch 34/100 | Loss: 0.037839 | Data: 0.037839 | PDE: 0.000000\n",
      "Epoch 35/100 | Loss: 0.037158 | Data: 0.037158 | PDE: 0.000000\n",
      "Epoch 36/100 | Loss: 0.036966 | Data: 0.036966 | PDE: 0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "velocity_map_fn = VelocityMapFn(waveform_encoder).to(device)\n",
    "\n",
    "epochs = 100   # å¥½ããªã‚¨ãƒãƒƒã‚¯æ•°ã«å¤‰æ›´\n",
    "\n",
    "\n",
    "losses_total = []\n",
    "losses_data  = []\n",
    "losses_pde   = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    velocity_map_fn.train()\n",
    "    waveform_encoder.train()\n",
    "    running_loss     = 0.0\n",
    "    running_loss_data = 0.0\n",
    "    running_loss_pde  = 0.0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        batch_size = xb.shape[0]\n",
    "        xzt = sample_coords(batch_size=batch_size).to(device)\n",
    "\n",
    "        residual = compute_pde_residual(model, velocity_map_fn, xb, xzt)\n",
    "        loss_pde = (residual**2).mean()\n",
    "\n",
    "        v_pred = waveform_encoder(xb)\n",
    "        loss_data = F.mse_loss(v_pred, yb)\n",
    "\n",
    "        loss = loss_data + 0.01 * loss_pde\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss     += loss.item() * batch_size\n",
    "        running_loss_data += loss_data.item() * batch_size\n",
    "        running_loss_pde  += loss_pde.item() * batch_size\n",
    "\n",
    "    epoch_loss     = running_loss / len(train_loader.dataset)\n",
    "    epoch_loss_data = running_loss_data / len(train_loader.dataset)\n",
    "    epoch_loss_pde  = running_loss_pde / len(train_loader.dataset)\n",
    "\n",
    "    losses_total.append(epoch_loss)\n",
    "    losses_data.append(epoch_loss_data)\n",
    "    losses_pde.append(epoch_loss_pde)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss:.6f} | Data: {epoch_loss_data:.6f} | PDE: {epoch_loss_pde:.6f}\")\n",
    "\n",
    "\n",
    "    # ---ï¼ˆå¿…è¦ãªã‚‰val_loaderã§ã‚‚æ¤œè¨¼ãƒ«ãƒ¼ãƒ—ã‚’å›ã™ï¼‰---\n",
    "\n",
    "print(\"Training finished!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02559bf3-3901-4f54-918a-a324477f0ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(losses_total, label='Total Loss')\n",
    "plt.plot(losses_data,  label='Data Loss (MSE)')\n",
    "plt.plot([0.01 * x for x in losses_pde], label='PDE Loss (scaled x0.01)')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28761253-7daf-4175-978f-b73c1077249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# äºˆæ¸¬ç”¨: ãƒ¢ãƒ‡ãƒ«ã‚’æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã«\n",
    "waveform_encoder.eval()\n",
    "\n",
    "n_show = 5  # è¡¨ç¤ºã—ãŸã„ã‚µãƒ³ãƒ—ãƒ«æ•°\n",
    "\n",
    "with torch.no_grad():\n",
    "    xb, yb = next(iter(val_loader))\n",
    "    xb = xb.to(device)\n",
    "    yb = yb.to(device)\n",
    "    v_pred = waveform_encoder(xb)  # [B,1,70,70]\n",
    "\n",
    "# æç”»\n",
    "fig, axes = plt.subplots(n_show, 2, figsize=(8, n_show*3))\n",
    "\n",
    "for i in range(n_show):\n",
    "    # 0ç•ªç›®ã‹ã‚‰n_showç•ªç›®ã¾ã§\n",
    "    pred_img = v_pred[i, 0].detach().cpu().numpy()  # [70,70]\n",
    "    gt_img   = yb[i, 0].detach().cpu().numpy()      # [70,70]\n",
    "\n",
    "    # æ­£è§£\n",
    "    ax_gt = axes[i, 0]\n",
    "    im_gt = ax_gt.imshow(gt_img, cmap=\"jet\", aspect='auto')\n",
    "    ax_gt.set_title(f\"Ground Truth #{i}\")\n",
    "    fig.colorbar(im_gt, ax=ax_gt, fraction=0.046, pad=0.04)\n",
    "    ax_gt.axis(\"off\")\n",
    "\n",
    "    # äºˆæ¸¬\n",
    "    ax_pred = axes[i, 1]\n",
    "    im_pred = ax_pred.imshow(pred_img, cmap=\"jet\", aspect='auto')\n",
    "    ax_pred.set_title(f\"Prediction #{i}\")\n",
    "    fig.colorbar(im_pred, ax=ax_pred, fraction=0.046, pad=0.04)\n",
    "    ax_pred.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93aaa07-ba63-46ea-9500-f63a1e4b4a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
