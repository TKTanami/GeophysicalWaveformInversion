{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# ── 1. small_batches フォルダから全バッチをロード ──\n",
    "batch_dir = \"./small_batches\"\n",
    "wave_files = sorted([os.path.join(batch_dir, f) for f in os.listdir(batch_dir) if f.startswith(\"waves\")])\n",
    "vel_files  = sorted([os.path.join(batch_dir, f) for f in os.listdir(batch_dir) if f.startswith(\"vels\")])\n",
    "\n",
    "# 全バッチを連結して大きな配列に\n",
    "all_waves = np.concatenate([np.load(p) for p in wave_files], axis=0)  # (10000,5,1000,70)\n",
    "all_vels  = np.concatenate([np.load(p) for p in vel_files],  axis=0)  # (10000,1,70,70)\n",
    "\n",
    "assert all_waves.shape[0] == all_vels.shape[0]\n",
    "N = all_waves.shape[0]\n",
    "\n",
    "# ── 2. train/val インデックスをランダムに分割 ──\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 例えば 80% を train、20% を val\n",
    "idx = np.arange(N)\n",
    "train_idx, val_idx = train_test_split(idx, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# ── 3. 分割後のデータを各配列に取り出して保存 ──\n",
    "os.makedirs(\"./dataset\", exist_ok=True)\n",
    "\n",
    "# train\n",
    "np.save(\"./dataset/train_waves.npy\", all_waves[train_idx])\n",
    "np.save(\"./dataset/train_vels.npy\",  all_vels[train_idx])\n",
    "print(\"Train set:\", all_waves[train_idx].shape, all_vels[train_idx].shape)\n",
    "\n",
    "# val\n",
    "np.save(\"./dataset/val_waves.npy\", all_waves[val_idx])\n",
    "np.save(\"./dataset/val_vels.npy\",  all_vels[val_idx])\n",
    "print(\"Val set:  \", all_waves[val_idx].shape,  all_vels[val_idx].shape)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
